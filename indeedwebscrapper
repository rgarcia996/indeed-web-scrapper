import requests
from bs4 import BeautifulSoup
import pandas as pd

def extract(page):
   miles = '50'
   state = 'TX'
   city = 'Plano'
   JobTitle = 'Information Security'
   headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}
   url = f'https://www.indeed.com/jobs?q={JobTitle}&l={city}%2C%20{state}&radius={miles}&start={page}'
   r = requests.get(url, headers)
   soup = BeautifulSoup(r.content, 'html.parser')
   return soup
   
def FromPageToArray(soup):

   divs = soup.find_all('a', class_ = 'tapItem') 

   print(len(divs)) #How many items per page, bugs out sometimes and gets 0 items from a page, not sure why lol
    
   for item in divs:
     
      title = item.find('h2').text.strip()

      company = item.find('span', class_ = 'companyName').text.strip()

      try:
         location = item.find('div', class_ = 'companyLocation').text.strip()
      except:
         location = ' No Location ' 

      try:
         pay = item.find('div', class_ = 'metadata salary-snippet-container').text.strip()
      except:
         pay = ' No Info '
            
      try:
         summary = item.find('div', class_ = 'job-snippet').text.strip()
      except:
         summary = ' No Description '
    
      link = item.get('href')

      job = {
            'Title ' : title,
            'Company ' : company,
            'Location ' : location,
            'Pay ' : pay,
            'Summary' : summary,
            'link ' : 'https://www.indeed.com' + link
      }
      
      joblist.append(job)
      
   return
   
joblist = []

p = 0

for i in range(0,50,10):
    
    p += 10
    
    print(f'Getting page, {i}')
    
    c = extract(p)
    
    FromPageToArray(c)
     
df = pd.DataFrame(joblist)   

df.to_csv('jobsbyraul.csv')
